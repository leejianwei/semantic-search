{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdb0a43",
   "metadata": {},
   "source": [
    "# Semantic Search with Amazon OpenSearch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca690e1",
   "metadata": {},
   "source": [
    "Now that we've been able to search the data set with a keyword search, let's see how we can use Semantic Search to improve the matches. To do this, we will add a vector representation of the questions to our data set in OpenSearch, then do the same with our sample query \"Does this work with xbox?\". In OpenSearch, we'll use a KNN search to find matches based on a cosine similarity rating on the vector data.\n",
    "\n",
    "![word vector](word2vec.png)\n",
    "\n",
    "\n",
    "We will:\n",
    "1. Use a HuggingFace BERT model to generate vector data for the PQA dataset\n",
    "2. Upload the dataset to OpenSearch, with the original question and answer text combined with the vector representation of the questions.\n",
    "3. Translate the query question to a vector.\n",
    "4. Perform a KNN search in OpenSearch to perform semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e02e76",
   "metadata": {},
   "source": [
    "### 1. Upgrade PyTorch and restart Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89571ee5",
   "metadata": {},
   "source": [
    "Before we begin, let's check if we need to update PyTorch. If you already completed Module 1, you should have already upgrade PyTorch, the version should already be 1.10.2 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f05a5",
   "metadata": {},
   "source": [
    "If the PyTorch version is 1.10.2 or higher, you can skip to step 2.\n",
    "\n",
    "If the PyTorch version is not 1.10.2 or higher, we need to update PyTorch and restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25331724",
   "metadata": {},
   "source": [
    "Let's recheck the version of Torch to ensure everything is up to date. The version should be 1.10.2 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb8600",
   "metadata": {},
   "source": [
    "### 2. Install additional libraries\n",
    "\n",
    "Now let's install some additional libraries we'll need later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q install transformers[torch]\n",
    "!pip install -U sentence-transformers rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24048ee9",
   "metadata": {},
   "source": [
    "### 3. Initialize boto3\n",
    "\n",
    "We will use boto3 to interact with other AWS services.\n",
    "\n",
    "Note: You can ignore any PythonDeprecationWarning warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6987b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "s3 = boto3.client('s3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac6694",
   "metadata": {},
   "source": [
    "### 4. Get Cloud Formation stack output variables\n",
    "\n",
    "We also need to grab some key values from the infrastructure we provisioned using CloudFormation. To do this, we will list the outputs from the stack and store this in \"outputs\" to be used later.\n",
    "\n",
    "#### Note : The following refers the stack by name. If you didn't use the default stack name, please update the value of \"cloudformation_stack_name\" to the Cloud Formation stack name you specified when you provisioned your environment.\n",
    "\n",
    "You can ignore any \"PythonDeprecationWarning\" warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"static-cloudformation-semantic-search\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "\n",
    "bucket = outputs['s3BucketTraining']\n",
    "aos_host = outputs['OpenSearchDomainEndpoint']\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751215fd",
   "metadata": {},
   "source": [
    "### 5. Prepare BERT Model \n",
    "\n",
    "For this module, we will be using the HuggingFace BERT model to generate vectorization data, where every sentence is 768 dimension data. Let's create some helper functions we'll use later on.\n",
    "![BERT](nlp_bert.png)\n",
    "\n",
    "We are creating 2 functions:\n",
    "1. mean_pooling\n",
    "2. sentence_to_vector - this is the key function we'll use to generate our vector data for the headset PQA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7871d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "#model_name = \"distilbert-base-uncased\"\n",
    "#model_name = \"sentence-transformers/msmarco-distilbert-base-dot-prod-v3\"\n",
    "model_name = \"sentence-transformers/distilbert-base-nli-stsb-mean-tokens\"\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "def sentence_to_vector(raw_inputs):\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    model = DistilBertModel.from_pretrained(model_name)\n",
    "    inputs_tokens = tokenizer(raw_inputs, padding=True, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs_tokens)\n",
    "\n",
    "    sentence_embeddings = mean_pooling(outputs, inputs_tokens['attention_mask'])\n",
    "    return sentence_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced4774",
   "metadata": {},
   "source": [
    "### 6. Prepare Headset PQA data\n",
    "We have already downloaded the dataset in Module 2, so let's start by ingesting 1000 rows of the data into a Pandas data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afe0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_pqa(file_name,number_rows=1000):\n",
    "    qa_list = []\n",
    "    df = pd.DataFrame(columns=('question', 'answer'))\n",
    "    with open(file_name) as f:\n",
    "        i=0\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            df.loc[i] = [data['question_text'],data['answers'][0]['answer_text']]\n",
    "            i+=1\n",
    "            if(i == number_rows):\n",
    "                break\n",
    "    return df\n",
    "\n",
    "\n",
    "qa_list = load_pqa('amazon-pqa/amazon_pqa_headsets.json',number_rows=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ac3e65",
   "metadata": {},
   "source": [
    "### 7. Convert the text data into vector data\n",
    "Using the helper function we created earlier, let's convert the questions from the Headset PQA dataset into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_sentences = sentence_to_vector(qa_list[\"question\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fcd69",
   "metadata": {},
   "source": [
    "### 8. Create an OpenSearch cluster connection.\n",
    "Next, we'll use Python API to set up connection with OpenSearch Cluster.\n",
    "\n",
    "Note: if you're using a region other than us-east-1, please update the region in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ebc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "import boto3\n",
    "\n",
    "region = 'us-east-1' \n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region)\n",
    "index_name = 'nlp_pqa'\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{'host': aos_host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e2106",
   "metadata": {},
   "source": [
    "### 9. Create a index in OpenSearch \n",
    "Whereas we previously created an index with 2 fields, this time we'll define the index with 3 fiels: the first field ' question_vector' holds the vector representation of the question, the second is the \"question\" for raw sentence and the third field is \"answer\" for the raw answer data.\n",
    "\n",
    "To create the index, we first define the index in JSON, then use the aos_client connection we initiated ealier to create the index in OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bedb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.space_type\": \"cosinesimil\",\n",
    "        \"analysis\": {\n",
    "          \"analyzer\": {\n",
    "            \"default\": {\n",
    "              \"type\": \"standard\",\n",
    "              \"stopwords\": \"_english_\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 768,\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"question\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c2dcd",
   "metadata": {},
   "source": [
    "If for any reason you need to recreate your dataset, you can uncomment and execute the following to delete any previously created indexes. If this is the first time you're running this, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa832e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aos_client.indices.delete(index=\"nlp_pqa\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa237b26",
   "metadata": {},
   "source": [
    "Using the above index definition, we now need to create the index in Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a981f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.create(index=\"nlp_pqa\",body=knn_index,ignore=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1382fc71",
   "metadata": {},
   "source": [
    "Let's verify the created index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=\"nlp_pqa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31ed5e",
   "metadata": {},
   "source": [
    "### 10. Load the raw data into the Index\n",
    "Next, let's load the headset enhanced PQA data into the index we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for c in qa_list[\"question\"].tolist():\n",
    "    content=c\n",
    "    vector=vector_sentences[i].tolist()\n",
    "    answer=qa_list[\"answer\"][i]\n",
    "    i+=1\n",
    "    aos_client.index(index='nlp_pqa',body={\"question_vector\": vector, \"question\": content,\"answer\":answer})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32c993",
   "metadata": {},
   "source": [
    "To validate the load, we'll query the number of documents number in the index. We should have 1000 hits in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=\"nlp_pqa\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b528b0",
   "metadata": {},
   "source": [
    "### 11. Generate vector data for user input query \n",
    "\n",
    "Next, we'll use the same helper function to translate our input question \"does this work with xbox?\" into a vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73004087",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_raw_sentences = ['does this work with xbox?']\n",
    "search_vector = sentence_to_vector(query_raw_sentences)[0].tolist()\n",
    "search_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4701a1",
   "metadata": {},
   "source": [
    "### 12. Search vector data with \"Semanatic Search\" \n",
    "\n",
    "Now that we have vector data in OpenSearch and a vector for our query question, let's perform a KNN search in OpenSearch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a0afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query={\n",
    "    \"size\": 50,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"question_vector\":{\n",
    "                \"vector\":search_vector,\n",
    "                \"k\":50\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=\"nlp_pqa\", \n",
    "                       body=query,\n",
    "                       stored_fields=[\"question\",\"answer\"])\n",
    "#print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['fields']['question'][0],hit['fields']['answer'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"question\",\"answer\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f1949",
   "metadata": {},
   "source": [
    "### 13. Search the same query with \"Keyword Search\"\n",
    "\n",
    "Let's repeat the same query with a keyword search and compare the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "query={\n",
    "    \"size\": 50,\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"question\":\"does this work with xbox?\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=\"nlp_pqa\", \n",
    "                       body=query,\n",
    "                       stored_fields=[\"question\",\"answer\"])\n",
    "#print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['fields']['question'][0],hit['fields']['answer'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"question\",\"answer\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733b3b5",
   "metadata": {},
   "source": [
    "### 14. Observe The Results\n",
    "\n",
    "Compare the first few records in the two searches above. For the Semantic search, the first 10 or so results are very similar to our input questions, as we expect. Compare this to keyword search, where the results quickly start to deviate from our search query (e.g. \"it shows xbox 360. Does it work for ps3 as well?\" - this matches on keywords but has a different meaning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4acec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
