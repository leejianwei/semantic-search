{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c587bad",
   "metadata": {},
   "source": [
    "# Module 2: Keyword Search with Amazon OpenSearch \n",
    "\n",
    "In this module, we are going to perform a simple search in OpenSearch by matching the individual words in our search query. We will:\n",
    "1. Load data into OpenSearch from the Amazon Product Question and Answer (PQA) dataset. This dataset contains a list of common questions and answers related to products.\n",
    "2. Query the data using a simple query search for find potentially matching questions. We will search the PQA dataset for questions similar to our sample question \"does this work with xbox?\". We expect to find matches in the dataset based on the individual words such as \"xbox\" and \"work\".\n",
    "\n",
    "In subsequent modules, we will then demonstrate how to use semantic search to improve the relvance of the query results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b5724",
   "metadata": {},
   "source": [
    "### 1. Install required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f606155",
   "metadata": {},
   "source": [
    "Before we begin, we need to install some required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9508ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q boto3\n",
    "!pip install -q requests\n",
    "!pip install -q requests-aws4auth\n",
    "!pip install -q opensearch-py\n",
    "!pip install -q tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7082e9",
   "metadata": {},
   "source": [
    "### 2. Get Cloud Formation stack output variables\n",
    "\n",
    "We also need to grab some key values from the infrastructure we provisioned using CloudFormation. To do this, we will list the outputs from the stack and store this in \"outputs\" to be used later.\n",
    "\n",
    "#### Note : The following refers the stack by name. If you didn't use the default stack name, please update the value of \"cloudformation_stack_name\" to the Cloud Formation stack name you specified when you provisioned your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832783dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"static-cloudformation-semantic-search\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "\n",
    "bucket = outputs['s3BucketTraining']\n",
    "aos_host = outputs['DomainEndpoint']\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b75cf8",
   "metadata": {},
   "source": [
    "### 3. Copy the data set locally\n",
    "Before we can run any queries, we need to load the Amazon Product Question and Answer data from : https://registry.opendata.aws/amazon-pqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32656f48",
   "metadata": {},
   "source": [
    "Let's start by having a look at all the files in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daacbd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls --no-sign-request s3://amazon-pqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c24aaf",
   "metadata": {},
   "source": [
    "There's a lot of data here, so for the purposes of this demo, we focus on just the headset data. Let's copy the amazon_pqa_headsets.json data locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --no-sign-request s3://amazon-pqa/amazon_pqa_headsets.json ./amazon-pqa/amazon_pqa_headsets.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f01c1",
   "metadata": {},
   "source": [
    "### 4. Create an OpenSearch cluster connection.\n",
    "Next, we'll use Python API to set up connection with OpenSearch Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4dcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "import boto3\n",
    "\n",
    "#es_host = 'search-semanti-domain-7fc1mmzarfpg-vtklyjm33bhijjarsdhbyl7jxq.us-east-1.es.amazonaws.com' \n",
    "region = 'us-east-1' \n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region)\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{'host': aos_host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2fe5ba",
   "metadata": {},
   "source": [
    "### 5. Create a index in OpenSearch \n",
    "We are defining an index with 2 fields: the first field is the \"content\" for raw sentence and the second field is \"answer\" for the raw answer data.\n",
    "\n",
    "To create the index, we first define the index in JSON, then use the aos_client connection we initiated ealier to create the index in OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_index = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "          \"analyzer\": {\n",
    "            \"default\": {\n",
    "              \"type\": \"standard\",\n",
    "              \"stopwords\": \"_english_\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948cccf9",
   "metadata": {},
   "source": [
    "If for any reason you need to recreate your dataset, you can uncomment and execute the following to delete any previously created indexes. If this is the first time you're running this, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d07900",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.delete(index=\"keyword_pqa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c09dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.create(index=\"keyword_pqa\",body=keyword_index,ignore=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33fd8dd",
   "metadata": {},
   "source": [
    "Let's verify the created index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=\"keyword_pqa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422b440",
   "metadata": {},
   "source": [
    "### 6. Load the raw data into the Index\n",
    "Next, let's load the headset PQA data we copied locally into the index we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f316b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "\n",
    "def load_pqa_as_json(file_name,number_rows=1000):\n",
    "    result=[]\n",
    "    with open(file_name) as f:\n",
    "        i=0\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            result.append(data)\n",
    "            i+=1\n",
    "            if(i == number_rows):\n",
    "                break\n",
    "    return result\n",
    "\n",
    "\n",
    "qa_list_json = load_pqa_as_json('amazon-pqa/amazon_pqa_headsets.json',number_rows=1000)\n",
    "\n",
    "\n",
    "def es_import(question):\n",
    "    aos_client.index(index='keyword_pqa',\n",
    "             body={\"question\": question[\"question_text\"],\"answer\":question[\"answers\"][0][\"answer_text\"]}\n",
    "            )\n",
    "        \n",
    "workers = 4 * cpu_count()\n",
    "    \n",
    "process_map(es_import, qa_list_json, max_workers=workers,chunksize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612806dc",
   "metadata": {},
   "source": [
    "To validate the load, we'll query the number of documents number in the index. We should have 1000 hits in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=\"keyword_pqa\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Got %d Hits\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81435b2",
   "metadata": {},
   "source": [
    "### 7. Run a \"Keyword Search\" in OpenSearch\n",
    "\n",
    "The following will execute a simple keyword search in OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d90512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query={\n",
    "    \"size\": 50,\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"question\":\"does this work with xbox?\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=\"keyword_pqa\", \n",
    "                       body=query,\n",
    "                       stored_fields=[\"question\",\"answer\"])\n",
    "#print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['fields']['question'][0],hit['fields']['answer'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"question\",\"answer\"])\n",
    "display(query_result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2482cc",
   "metadata": {},
   "source": [
    "Congratulations, you've now executed a simple keyword search on the data in OpenSearch.\n",
    "\n",
    "If you take a look at the results above, you'll notice that the results match one or more of the key words from our question, most commonly the words \"work\" and \"xbox\".  You'll also notices that a lot of these results aren't relevant to our original question, such as \"Does it work on PS3?\" and \"Does it work for computers\". In Module 3, we'll instead use semantic search to make the result more relevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
